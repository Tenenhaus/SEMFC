---
title: "R Notebook"
output: html_notebook
---



```{r}

library(lavaan)
source('data/data_generated_reflective.R')



# X = X_2
# Y = Y_2

sem.model <-'
# latent variable definitions
eta1 =~ X11+X12+X13+X14+X15+X16+X17+X18+X19
eta2 =~ X21+X22+X23
eta3 =~ X31+X32+X33
eta4 =~ X41+X42+X43
eta5 =~ X51+X52+X53
eta6 =~ X61+X62+X63

# Regressions
eta5 ~ eta1 + eta2 + eta6
eta6 ~ eta3 + eta4 + eta5

# residual covariances
eta5 ~~ eta6

#variance



'








sem.pen.model <-  '
# latent variable definitions
eta1 =~ X11
eta2 =~ X21 + X22+X23
eta3 =~ X31+X32+X33
eta4 =~ X41+X42+X43
eta5 =~ X51+X52+X53
eta6 =~ X61+ X62+X63

# penalisation
pen() * eta1 =~ X12 +X13 +X14+X15+X16+X17+X18+X19

# Regressions
eta5 ~ eta1 + eta2 + eta6
eta6 ~ eta3 + eta4 + eta5

#variance

eta1 ~~ 1*eta1
eta2 ~~ 1*eta2
eta3 ~~ 1*eta3
eta4 ~~ 1*eta4
eta5 ~~ 1*eta5
eta6 ~~ 1*eta6




# residual covariances
eta5 ~~ eta6


'

out <- sem(sem.model, X)
summary(out)
```


```{r}
library(lslx)
```


```{r}
lslx_fa <- lslx$new(model = sem.pen.model, data = X)
lslx_fa$fit(
  penalty_method = "mcp",
  lambda_grid = exp(seq(log(0.001), log(1), length.out = 10)),
  delta_grid = c(1, 1.5, 2, 3, 5, 10, Inf)
)

```
```{r}
lslx_fa$summarize(selector = "bic", interval = FALSE)
```




```{r}
library(regsem)
```



```{r}
# extractMatrices(out)$A
out.reg <- cv_regsem(out, type="lasso", pars_pen = 2:8,n.lambda=23,jump=.05)
head(round(out.reg$parameters,2),5)
head(round(out.reg$fits,2))
plot(out.reg,show.minimum="BIC")
out.reg$final_pars
summary(out.reg)

```














```{r}
library(lessSEM)
```

```{r}

lavaanSyntax <-'
# latent variable definitions
eta1 =~ X11+X12+l0*X13+ l1*X14+l2*X15+l3*X16 + l4*X17
eta2 =~ X21+X22+X23
eta3 =~ X31+X32+X33
eta4 =~ X41+X42+X43
eta5 =~ X51+X52+X53
eta6 =~ X61+X62+X63

# Regressions
eta5 ~ eta1 + eta2 + eta6
eta6 ~ eta3 + eta4 + eta5

# residual covariances
eta5 ~~ eta6

'

lavaanModel <- lavaan::sem(lavaanSyntax,
                           data = X)


lsem <- lasso(
  # pass the fitted lavaan model
  lavaanModel = lavaanModel,
  # names of the regularized parameters:
  regularized = c("l0", "l1", "l2", "l3", "l4"),
  # in case of lasso and adaptive lasso, we can specify the number of lambda
  # values to use. lessSEM will automatically find lambda_max and fit
  # models for nLambda values between 0 and lambda_max. For the other
  # penalty functions, lambdas must be specified explicitly
  nLambdas = 50)



```
```{r}
plot(lsem)
```
```{r}
# coef(lsem)
# coef(lsem, criterion = "AIC")



coef(lsem, criterion = "BIC")
estimates(lsem, criterion = "BIC")

```




```{r}
library(PMA)
```
```{r}
 u <- matrix(c(rnorm(50), rep(0,150)),
 ncol=1)
 v <- matrix(c(rnorm(75),rep(0,225)), ncol=1)
 x <- u%*%t(v)+ matrix(rnorm(200*300),ncol=300)
res <- svd(x,1,1)
```
```{r}
cv.out <- PMD.cv(x, type="standard", sumabss=seq(0.1, 0.6, len=20))
print(cv.out)
plot(cv.out)
```
```{r}
out <- PMD(x, type="standard", sumabs=cv.out$bestsumabs, K=1, v=cv.out$v.init)
print(out)
par(mfrow=c(2,2))
par(mar=c(2,2,2,2))
plot(out$u[,1], main="Est. u")
plot(out$v[,1], main="Est. v")
plot(u, main="True u")
plot(v, main="True v")
plot(res$u[,1], main="svd. u")
plot(res$v[,1], main="svd. v")
plot(u, main="True u")
plot(v, main="True v")
 # And if we want to cont
```
```{r}
out2 <- PMD(x, type="standard", K=2, sumabsu=6, sumabsv=8, v=out$v.init,
cnames=paste("v", sep=" ", 1:ncol(x)), rnames=paste("u", sep=" ", 1:nrow(x)))
print(out2)
```

```{r}
cbind(res$u, u, abs(res$u - u ),out$u, u , abs(out$u - u ))
```
```{r}
set.seed(123)

# Données simulées
X <- matrix(rnorm(100*10), nrow = 100, ncol = 10)
S <- cov(X)   # matrice de covariance (symétrique 10x10)

# --- Cas 1 : Sparse PCA via SPC ---
spc_res <- SPC(S, sumabsv = 3, K = 1)
cat("SPC result (u):\n")
print(round(spc_res$v, 3))   # vecteur sparse

# --- Cas 2 : PMD avec aucune pénalisation sur u (équivaut à SPC) ---
pmd_res <- PMD(S, type="standard",
               sumabsu = sqrt(nrow(S)), # pas de pénalisation sur u
               sumabsv = 3,             # pénalisation sur v
               K = 1)
cat("\nPMD result (u and v):\n")
print(round(pmd_res$u, 3))
print(round(pmd_res$v, 3))

# --- Vérif que u et v sont identiques ---
all.equal(pmd_res$u, pmd_res$v)
```


```{r}
set.seed(123)


# 1) Générer un vecteur u non normalisé
p <- 10
u_orig <- c(2, -1.5, 0, 0, 1, rep(0, p-5))  # non normalisé
cat("u original (non normalisé) :\n")
print(round(u_orig, 3))

# 2) Construire X = u u^T + bruit
X <- u_orig %*% t(u_orig) + 0.1 * matrix(rnorm(p*p), p, p)
X <- (X + t(X))/2  # symétriser






# 3) Appliquer PMD pour retrouver un vecteur normalisé
res <- PMD(X, type="standard",
           sumabsu = 3,  # pas de pénalisation sur u
           sumabsv = 3,        # pénalisation sur v
           K = 1)
u_hat <- res$v          # vecteur normalisé
cat("\nVecteur estimé par PMD (normalisé) :\n")
print(round(u_hat, 3))

# 4) Reconstruire l'échelle pour retrouver u original approximatif
# L'échelle est sqrt(valeur propre principale)
lambda_hat <- as.numeric(t(u_hat) %*% X %*% u_hat)
u_reconstructed <- sqrt(lambda_hat) * u_hat

cat("\nVecteur reconstruit avec échelle :\n")
print(round(u_reconstructed, 3))

# Comparaison avec u original
cat("\nCorrélation avec u original :\n")
print(cor(u_reconstructed, u_orig))
```
```{r}

p <- 10
u_orig <- c(2, -1.5, 0, 0, 1, rep(0, p-5))  # non normalisé
cat("u original (non normalisé) :\n")
print(round(u_orig, 3))

# 2) Construire X = u u^T + bruit
x <- u%*%t(u)+ matrix(rnorm(200*200),ncol=200)
x <- u%*%t(u)
x <- (x + t(x))/2  # symétriser



cv.out <- PMD.cv(x, type="standard", sumabss=seq(0.1, 0.6, len=20))

out <- PMD(x, type="standard", sumabs=cv.out$bestsumabs, K=1, v=cv.out$v.init)

res <- svd(x, 1,1)


```
```{r}
cbind(-round(out$u*sqrt(out$d),2), round(u,2), -round(res$u*sqrt(res$d[[1]]),2))


```
```{r}
X1 = (t(Y$LV2) %*% Y$LV1)%*%t((t(Y$LV2) %*% Y$LV1))
X3 = (t(Y$LV2) %*% Y$LV3)%*%t((t(Y$LV2) %*% Y$LV3))
X4 = (t(Y$LV2) %*% Y$LV4)%*%t((t(Y$LV2) %*% Y$LV4))
X5 = (t(Y$LV2) %*% Y$LV5)%*%t((t(Y$LV2) %*% Y$LV5))
X6 = (t(Y$LV2) %*% Y$LV6)%*%t((t(Y$LV2) %*% Y$LV6))

X = X1+X3+X4+X5+X6
Z = cbind((t(Y$LV2) %*% Y$LV1), (t(Y$LV2) %*% Y$LV3), (t(Y$LV2) %*% Y$LV4), (t(Y$LV2) %*% Y$LV5),(t(Y$LV2) %*% Y$LV6))

A2 = (t(Y$LV1) %*% Y$LV2)%*%t((t(Y$LV1) %*% Y$LV2))
A3 = (t(Y$LV1) %*% Y$LV3)%*%t((t(Y$LV1) %*% Y$LV3))
A4 = (t(Y$LV1) %*% Y$LV4)%*%t((t(Y$LV1) %*% Y$LV4))
A5 = (t(Y$LV1) %*% Y$LV5)%*%t((t(Y$LV1) %*% Y$LV5))
A6 = (t(Y$LV1) %*% Y$LV6)%*%t((t(Y$LV1) %*% Y$LV6))

A = A2+A3+A4+A5+A6






cv.out <- PMD.cv(X, type="standard", sumabss=seq(1/sqrt(3), 1, len=20))

out <- PMD(X, type="standard", sumabs=cv.out$bestsumabs, K=1, v=cv.out$v.init)
out$v

cv.out <- SPC.cv(A, sumabsvs = seq(1, sqrt(ncol(A)), len=20))
out <- SPC(A,  sumabsv=cv.out$bestsumabsv, K=1, v=cv.out$v.init)
out$v


```
```{r}
library(elasticnet)
out2 <- spca(A, K=1, type='Gram', sparse="varnum", para=4)
out2$loadings

```




```{r}
library(RGCCA)




C <- matrix(c(0, 1, 1, 1, 1, 1,
             1, 0, 0, 0, 0, 0,
             1, 0, 0, 0, 0, 0,
             1, 0, 0, 0, 0, 0,
             1, 0, 0, 0, 0, 0,
             1, 0, 0, 0, 0, 0), 6, 6, byrow = TRUE)

C <- matrix(c(0, 1, 1, 1, 1, 0,
             1, 0, 1, 1, 1, 0,
             1, 1, 0, 1, 0, 1,
             1, 1, 1, 0, 0, 1,
             1, 1, 0, 0, 0, 1,
             0, 0, 1, 1, 1, 0), 6, 6, byrow = TRUE)






psvd <- function(x){
      data <- t(Y_2[[x]])%*%Reduce("cbind", Y_2[-x])%*%t(t(Y_2[[x]])%*%Reduce("cbind", Y_2[-x]))
      # data <- t(A[[x]])%*%Reduce("cbind", A[-x])  u et v peuvent ne pas etre les memes attention



      cv.out <- SPC.cv(data, sumabsvs=seq(1, sqrt(ncol(data)), len=20))

      out <- SPC(data, sumabsv=cv.out$bestsumabsv, K=1, v=cv.out$v.init)

      return(out$v)


    }



fit_rgcca = rgcca(Y, scheme = "factorial")
fit_rgcca2 = rgcca(Y_2, scheme = "factorial")
fit_rgcca_sparse = rgcca(Y_2, scheme = "factorial", sparsity = c(0.4,1,1,1,1,1))

fit_rgcca_connexion = rgcca(Y_2,connection = C, scheme = "factorial", sparsity = 0.7)


a = sapply(1:6,
               function(x)
                 svd(t(Y_2[[x]])%*%Reduce("cbind", Y_2[-x]),
                     nu = 1, nv = 1)$u,
               simplify = FALSE
               )


apmd = sapply(1:6,
               function(x)
                 psvd(x),
               simplify = FALSE
               )





sparse_svd.cv <- function(L, pen, len_seq, nfold, niter){

  res <-  list()

  for (x in 1:length(L)){
    if (pen[[x]] == 1){
      data <- t(L[[x]])%*%Reduce("cbind", L[-x])%*%t(t(L[[x]])%*%Reduce("cbind", L[-x]))
      cv.out <- SPC.cv(data, sumabsvs=seq(1, sqrt(ncol(data)), len=len_seq), nfold = nfold, niter =niter)
      print(cv.out$bestsumabsv)
      out <- SPC(data, sumabsv=cv.out$bestsumabsv, K=1, v=cv.out$v.init)$v

      res[[x]] <- out

    }

  }

  return (res)

}


sparse_svd <- function(L, pen, values){

  res <-  list()

  for (x in 1:length(L)){
    if (pen[[x]] == 1){
      data <- t(L[[x]])%*%Reduce("cbind", L[-x])%*%t(t(L[[x]])%*%Reduce("cbind", L[-x]))
      out <- SPC(data, sumabsv=values[[x]], K=1)$v

      res[[x]] <- out

    }
  }

  return (res)

}




res = sparse_svd(Y_2, c(1,1,0,0,0,0), c(7.5,sqrt(3),0,0,0,0))


res.cv = sparse_svd.cv(Y_2, c(1,0,0,0,0,0), 50,20,30)


```
```{r}
list_a_padded <- lapply(fit_rgcca$a, function(x) {
  length(x) <- 160
  x
})

do.call(cbind, list_a_padded)


```
```{r}
list_a_padded2 <- lapply(fit_rgcca2$a, function(x) {
  length(x) <- 150
  x
})

do.call(cbind, list_a_padded2)
```
```{r}
list_a_padded3 <- lapply(a, function(x) {
  length(x) <- 150
  x
})

do.call(cbind, list_a_padded3)
```
```{r}
list_a_padded4 <- lapply(fit_rgcca_connexion$a, function(x) {
  length(x) <- 150
  x
})

do.call(cbind, list_a_padded4)
```
```{r}
list_a_padded4 <- lapply(fit_rgcca_sparse$a, function(x) {
  length(x) <- 151
  x
})

do.call(cbind, list_a_padded4)
```
```{r}
list_a_padded5 <- lapply(apmd, function(x) {
  length(x) <- 151
  x
})

do.call(cbind, list_a_padded5)
```
```{r}
perm_out = rgcca_permutation(Y_2, scheme = "factorial", par_type = "sparsity", par_value = cbind(seq(0.15, 1, length = 50), 1, 1, 1, 1, 1), n_perms = 10)
xx = rgcca(perm_out)
plot(xx$a[[1]])
```
```{r}
yy = rgcca(Y_2, sparsity = c(0.93,1 ,1,1,1,1))
plot(yy$a[[1]])
```
