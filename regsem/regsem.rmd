---
title: "R Notebook"
output: html_notebook
---

```{r}
# install.packages("lslx", dependencies = TRUE)
```

```{r}


source('data/data_generated_reflective.R')

n_row <- nrow(X)

pen1 <- rnorm(n_row)
pen2 <- rnorm(n_row)
pen3 <- rnorm(n_row)

Xpen <- cbind(X, pen1, pen2, pen3)


sem.model <-'
# latent variable definitions
eta1 =~ X11+X12+X13
eta2 =~ X21+X22+X23
eta3 =~ X31+X32+X33
eta4 =~ X41+X42+X43
eta5 =~ X51+X52+X53 + pen1+pen2+pen3
eta6 =~ X61+X62+X63+ pen1+pen2+pen3

# Regressions
eta5 ~ eta1 + eta2 + eta6
eta6 ~ eta3 + eta4 + eta5

# residual covariances
eta5 ~~ eta6

'








sem.pen.model <-  '
# latent variable definitions
eta1 =~ X11+X12+X13
eta2 =~ X21+X22+X23
eta3 =~ X31+X32+X33
eta4 =~ X41+X42+X43
eta5 =~ X51+X52+X53
eta6 =~ X61+ X62+X63

# penalisation
pen() * eta5 =~ pen1+pen2+pen3
pen() * eta6 =~ pen1+pen2+pen3

# Regressions
eta5 ~ eta1 + eta2 + eta6
eta6 ~ eta3 + eta4 + eta5

# residual covariances
eta5 ~~ eta6

# variances

eta1 ~~ 1 * eta1
eta2 ~~ 1 * eta2
eta3 ~~ 1 * eta3
eta4 ~~ 1 * eta4
eta5 ~~ 1 * eta5
eta6 ~~ 1 * eta6
'

out <- sem(sem.model, Xpen)

```


```{r}
library(lslx)
```


```{r}
lslx_fa <- lslx$new(model = sem.pen.model, data = Xpen)
lslx_fa$fit(penalty_method = "mcp",
            lambda_grid = seq(0.01, 0.60, 0.01),
            delta_grid = c(1.5, 3.0, Inf))

```
```{r}
result = lslx_fa$summarize(selector = "bic", interval = FALSE)
```




```{r}
library(regsem)
```



```{r}
# extractMatrices(out)$A
out.reg <- cv_regsem(out, type="lasso", pars_pen = c(11:13,16:18),n.lambda=23,jump=.05)
head(round(out.reg$parameters,2),5)
head(round(out.reg$fits,2))
plot(out.reg,show.minimum="BIC")
out.reg$final_pars
summary(out.reg)

```












```{r}
library(lessSEM)
```

```{r}

lavaanSyntax <-'
# latent variable definitions
eta1 =~ X11+X12+X13
eta2 =~ X21+X22+X23
eta3 =~ X31+X32+X33
eta4 =~ X41+X42+X43
eta5 =~ X51+X52+X53 + l1*pen1+l2*pen2+l3*pen3
eta6 =~ X61+X62+X63+ l4*pen1+l5*pen2+l6*pen3

# Regressions
eta5 ~ eta1 + eta2 + eta6
eta6 ~ eta3 + eta4 + eta5

# residual covariances
eta5 ~~ eta6

'

lavaanModel <- lavaan::sem(lavaanSyntax,
                           data = Xpen)


lsem <- lasso(
  # pass the fitted lavaan model
  lavaanModel = lavaanModel,
  # names of the regularized parameters:
  regularized = c("l1", "l2", "l3", "l4", "l5","l6"),
  # in case of lasso and adaptive lasso, we can specify the number of lambda
  # values to use. lessSEM will automatically find lambda_max and fit
  # models for nLambda values between 0 and lambda_max. For the other
  # penalty functions, lambdas must be specified explicitly
  nLambdas = 50)



```
```{r}
plot(lsem)
```
```{r}
# coef(lsem)
# coef(lsem, criterion = "AIC")



coef(lsem, criterion = "BIC")
estimates(lsem, criterion = "BIC")

```



```{r}
install.packages("PMA", dependencies = TRUE)




```
```{r}
library(PMA)
```
```{r}
 u <- matrix(c(rnorm(50), rep(0,150)),
 ncol=1)
 v <- matrix(c(rnorm(75),rep(0,225)), ncol=1)
 x <- u%*%t(v)+ matrix(rnorm(200*300),ncol=300)
```
```{r}
cv.out <- PMD.cv(x, type="standard", sumabss=seq(0.1, 0.6, len=20))
print(cv.out)
plot(cv.out)
```
```{r}
out <- PMD(x, type="standard", sumabs=cv.out$bestsumabs, K=1, v=cv.out$v.init)
print(out)
par(mfrow=c(2,2))
par(mar=c(2,2,2,2))
plot(out$u[,1], main="Est. u")
plot(out$v[,1], main="Est. v")
plot(u, main="True u")
plot(v, main="True v")
 # And if we want to cont
```
```{r}
out2 <- PMD(x, type="standard", K=2, sumabsu=6, sumabsv=8, v=out$v.init,
cnames=paste("v", sep=" ", 1:ncol(x)), rnames=paste("u", sep=" ", 1:nrow(x)))
print(out2)
```
```{r}
x <- u%*%t(v)
res = svd(x,1,1)
```
```{r}
cbind(res$u, u, out$u)
```
```{r}
u
```
